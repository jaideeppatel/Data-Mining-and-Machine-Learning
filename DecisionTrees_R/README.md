Decision Trees using Ginin Index and Infomation Gain:

The decision Treee is implemented from scratch using the Ginin index and Information gain as the splitting criteria.

Used 10 fold cross validation to obtain better accuracy performance.

Trained and trsted on 5 different datasets from the UCI Machine learning repository.

Sample Accuracy results:

Dataset Iris accuracy using Information gain: 
“Mean accuracy: “0.786667”

Dataset Haberman accuracy using information gain:
"Accuracy is: " "0.8"          

Dataset Haberman accuracy using Gini:
“Mean accuracy: “0.79”

Dataset Iris accuracy using Gini:
“Mean accuracy: “0.76”

The results above are as per the outputs using the 10 fold cross validation.
